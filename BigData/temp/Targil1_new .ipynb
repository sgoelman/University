{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TARGIL No. 1 \n",
    "# By Sahar Goelman\n",
    "# selected database: rasturants.csv\n",
    "#TODO: add link to the resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkShell, master=local[*]) created by <module> at C:\\Users\\sgoel\\Anaconda3\\lib\\site-packages\\IPython\\utils\\py3compat.py:188 ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8ae7904a8180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ex1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\spark\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    127\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mc:\\spark\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    326\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 328\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    329\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkShell, master=local[*]) created by <module> at C:\\Users\\sgoel\\Anaconda3\\lib\\site-packages\\IPython\\utils\\py3compat.py:188 "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "import os\n",
    "conf = SparkConf().setAppName(\"Ex1\")\n",
    "sc1 = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate that the database file exists otherwise break\n",
    "if  not os.path.isfile(\"resturants.csv\"):\n",
    "    print(\"please add resturants.csv to :\"+os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: business_id,business_name,business_address,business_city,business_state,business_postal_code,business_latitude,business_longitude,business_location,business_phone_number,inspection_id,inspection_date,inspection_score,inspection_type,violation_id,violation_description,risk_category,rand_code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows loaded: 53577\n"
     ]
    }
   ],
   "source": [
    "#question (1) loading the database\n",
    "csv = sc.textFile(\"resturants.csv\")\n",
    "\n",
    "csv_header = csv.first() \n",
    "print(\"Column names:\",format(csv_header))\n",
    "csv_data = csv.filter(lambda line : line != csv_header) #remove csv headers from data\n",
    "print(\"Number of rows loaded: {}\".format(csv.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FiveHeaders:\n",
    "    def __init__(self):\n",
    "        self.values = []\n",
    "        self.csv_header = dict()\n",
    "    def add_headers(self, key, val):\n",
    "        self.csv_header[key] = val\n",
    "    def get_header(self, key):\n",
    "        return self.csv_header[key]\n",
    "    def get_all_values(self):\n",
    "        self.values = list(self.csv_header.values())\n",
    "        return self.values\n",
    "    def get_index_from_key(self, key):\n",
    "        index_in_header = self.get_header(key)\n",
    "        self.values.index(index_in_header)\n",
    "        return self.values.index(index_in_header)\n",
    "\n",
    "\n",
    "split_headers= csv_header.split(\",\")\n",
    "fiveHeaders = FiveHeaders()\n",
    "headers = ['business_id'] #, 'business_id','business_id','business_id','business_id']\n",
    "# headers = ['inspection_score', 'business_id','inspection_id','business_postal_code', 'business_phone_number']\n",
    "for header in headers: \n",
    "     fiveHeaders.add_headers(header, split_headers.index(header))\n",
    "\n",
    "# fiveHeaders.get_header('inspection_score')\n",
    "fiveHeaders.get_all_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added unique id at column 0:\nfirst=: (0, ['39810', 'Cherry Blossom Bakery', '844 Clement St', 'San Francisco', 'CA', '94118', '37.782778', '-122.468341', '\"{\\'latitude\\': \\'37.782778\\'', \" 'needs_recoding': False\", ' \\'human_address\\': \\'{\"\"address\"\":\"\"\"\"', '\"\"city\"\":\"\"\"\"', '\"\"state\"\":\"\"\"\"', '\"\"zip\"\":\"\"\"\"}\\'', ' \\'longitude\\': \\'-122.468341\\'}\"', '', '39810_20160308', '2016-03-08T00:00:00', '77', 'Routine - Unscheduled', '39810_20160308_103124', 'Inadequately cleaned or sanitized food contact surfaces', 'Moderate Risk', '94119'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added unique id at column 0:\nfirst[1]: ['39810', 'Cherry Blossom Bakery', '844 Clement St', 'San Francisco', 'CA', '94118', '37.782778', '-122.468341', '\"{\\'latitude\\': \\'37.782778\\'', \" 'needs_recoding': False\", ' \\'human_address\\': \\'{\"\"address\"\":\"\"\"\"', '\"\"city\"\":\"\"\"\"', '\"\"state\"\":\"\"\"\"', '\"\"zip\"\":\"\"\"\"}\\'', ' \\'longitude\\': \\'-122.468341\\'}\"', '', '39810_20160308', '2016-03-08T00:00:00', '77', 'Routine - Unscheduled', '39810_20160308_103124', 'Inadequately cleaned or sanitized food contact surfaces', 'Moderate Risk', '94119']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added unique id at column 0:\nfirst[1][1]: Cherry Blossom Bakery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataBase: 53576\n"
     ]
    }
   ],
   "source": [
    "#problem number (2):\n",
    "\n",
    "#RDD is assumed to contain an (unique) index column at position 0\n",
    "def get_RDD_row_by_index(rdd, index=0):\n",
    "    nrows = rdd.count()\n",
    "    if index < nrows:\n",
    "        return rdd.filter(lambda kv: kv[0] == index)\n",
    "    return None\n",
    "\n",
    "#RDD is assumed to contain the requested col_nama\n",
    "def get_RDD_col_values(rdd, col_name):\n",
    "    col_index = fv.get_index_from_key(col_name)\n",
    "    return rdd.map(lambda line: line[1][col_index])\n",
    "\n",
    "\n",
    "#add a unique_id and split csv using commas\n",
    "baseData = csv_data.zipWithIndex().map(lambda line: (line[-1],line[:-1][0].split(\",\")))\n",
    "print(\"Added unique id at column 0:\\nfirst=: {}\".format(baseData.first()))\n",
    "print(\"Added unique id at column 0:\\nfirst[1]: {}\".format(baseData.first()[1]))\n",
    "print(\"Added unique id at column 0:\\nfirst[1][1]: {}\".format(baseData.first()[1][1]))\n",
    "#test our method to get the n'th row from RDD\n",
    "#print(\"take the {}th row from Data: {}\".format(75, get_RDD_row_by_index(baseData,75).first()))\n",
    "print('number of rows in dataBase: {}'.format(baseData.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header indexes are:[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd[100][0] = 63940\n"
     ]
    }
   ],
   "source": [
    "#problem number (3.a): unique values of the 5 columns \n",
    "#RDD is assumed to contain the requested col_name\n",
    "#row 0 is the first row\n",
    "def get_RDD_col_value(rdd, row_index, col_name):\n",
    "    print (\"header indexes are:{}\".format(fiveHeaders.get_all_values()))\n",
    "    col_index = fiveHeaders.get_index_from_key(col_name)\n",
    "    row = get_RDD_row_by_index(rdd, row_index)\n",
    "    val  = row.first()[1][col_index]\n",
    "    print (\"rdd[{}][{}] = {}\".format(row_index, col_index,val))\n",
    "\n",
    "\n",
    "get_RDD_col_value(baseData, 100, 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering data\n<__main__.Data_Filter object at 0x000002B9EE6FF160>\nend filtering data\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#allows counting only numerical columns\n",
    "class Data_Filter():\n",
    "    def __init__(self, header_name):\n",
    "        self.col_indexes = header_name.get_all_values()\n",
    "        self.build_line = self._builder(self.list_creator)\n",
    "        self.build_filter = self._builder(self.create_filter_is_num)\n",
    "        \n",
    "    def _builder(self, func):\n",
    "        return func(self.col_indexes)\n",
    "\n",
    "    def number(self, s):\n",
    "        ret = None\n",
    "        try:\n",
    "            ret = int(s)\n",
    "        except ValueError:\n",
    "            ret = float(s)\n",
    "        finally:\n",
    "            return ret\n",
    "\n",
    "    def is_not_number(self, s):\n",
    "        ret = False\n",
    "        try:\n",
    "            #print(\"value = \".format(s))\n",
    "            if (math.isnan(self.number(s))):  #not a number\n",
    "                ret = True\n",
    "        except:\n",
    "            print(\"exception in is_not_number, s = {}\".format(s))\n",
    "            ret = True\n",
    "        finally:\n",
    "            return ret\n",
    "\n",
    "    def list_creator(self, col_indexes):\n",
    "        def get_unique_line(_line, unique_id, append_num=True):\n",
    "            items = []\n",
    "            for col in col_indexes:\n",
    "                if append_num:\n",
    "                    item = self.number(_line[col])\n",
    "                else:\n",
    "                    item = _line[col]\n",
    "                items.append(item)\n",
    "            return (unique_id, items)\n",
    "        return get_unique_line\n",
    "\n",
    "\n",
    "    def create_filter_is_num(self, col_indexes):\n",
    "\n",
    "        def check_is_number(_line):\n",
    "            ret = True\n",
    "            for col in col_indexes:\n",
    "                try:\n",
    "                    #print (\"_line = {}\".format(_line))\n",
    "                    #print (\"value[{}]: {}\".format(col, _line[col]))\n",
    "                    if (math.isnan(self.number(_line[col]))):\n",
    "                        ret = False\n",
    "                except:\n",
    "                    #TODO\n",
    "                    print('create_filter_is_num caught an exception\\n _line[{}]={}'.format(col, _line[col]))\n",
    "                    ret = False\n",
    "            return ret\n",
    "        return check_is_number\n",
    "\n",
    "print (\"filtering data\")\n",
    "filtered_data = Data_Filter(fiveHeaders)\n",
    "print(filtered_data)\n",
    "print(\"end filtering data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of col_names[business_id] = 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for col_name in headers: \n",
    "    print(\"index of col_names[{}] = {}\".format(col_name,filtered_data.col_indexes[i]))\n",
    "    i = i + 1\n",
    "    \n",
    "filteredByColumn = baseData.filter(lambda line: filtered_data.build_filter(line[1])).map(lambda line: filtered_data.build_line(line[1], line[0]))\n",
    "\n",
    "def count_distinct(filter_by_column, headerName, key):\n",
    "    res =  filter_by_column.map(lambda pair: pair[1][headerName.get_index_from_key(key)]).distinct().count()\n",
    "    return res\n",
    "def print_distinct(col_name):\n",
    "        cnt = count_distinct(filteredByColumn, fiveHeaders, col_name)\n",
    "        print('Distint values of col: {} = {}'.format(col_name, cnt))\n",
    "        return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distint values of col: business_id = 6155\n"
     ]
    }
   ],
   "source": [
    "#Question 3/a\n",
    "col_distinct_counts = {}\n",
    "for header in headers:\n",
    "    res = print_distinct(header)\n",
    "    col_distinct_counts[header] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of column:business_id\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1368x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Utility functions to plot histogram\n",
    "class Histogram():\n",
    "\n",
    "    def show(self, col_name, color):\n",
    "        obj = self.countAggregateByKey(col_name)\n",
    "        self.plot(obj,color)\n",
    "    \n",
    "    def countAggregateByKey(self, col_name):\n",
    "        aggragateByKey = col_name.countByValue() \n",
    "        keys  = aggragateByKey.keys()\n",
    "        x_axis = np.array(sorted(keys))\n",
    "        y_axis = np.array([aggragateByKey.get(key) for key in x_axis])\n",
    "        return self.buildObj(x_axis,y_axis)\n",
    "    \n",
    "    def buildObj(self, x_axis,y_axis):\n",
    "        res = dict()\n",
    "        res['x'] = {\n",
    "            'pos': np.arange(len(x_axis)),\n",
    "            'x_axis':x_axis\n",
    "        }\n",
    "        res['y']={\n",
    "            'y_axis':y_axis\n",
    "        }\n",
    "        return res\n",
    "    \n",
    "    def plot(self, obj,color):\n",
    "        y_axis = obj['y']['y_axis']\n",
    "        pos = obj['x']['pos']\n",
    "        x_axis = obj['x']['x_axis']\n",
    "\n",
    "        ax = plt.axes()\n",
    "        ax.set_xticks(pos)\n",
    "        ax.set_xticklabels(x_axis)\n",
    "\n",
    "        plt.bar(pos, y_axis, 0.5, color=color)\n",
    "        plt.xticks(size=16)\n",
    "\n",
    "        fig = matplotlib.pyplot.gcf()\n",
    "        fig.set_size_inches(19, 5)\n",
    "        plt.show()\n",
    "\n",
    "#Question 3/b drawing histograms of the 5 columns\n",
    "# get all indexes for a specific col name\n",
    "# we normalize the \"inpection_score\" variable so that \n",
    "def filterColumnByHeader(filteredByColumn,col_names,key):\n",
    "    return filteredByColumn.map(lambda pair: pair[1][col_names.get_index_from_key(key)])\n",
    "\n",
    "histogram_colors = ['red', 'green', 'blue', 'yellow', 'magenta']\n",
    "i = 0\n",
    "h = Histogram()\n",
    "for header in headers:\n",
    "    data = filterColumnByHeader(filteredByColumn,fiveHeaders,header)#\n",
    "    print (\"Histogram of column:{}\".format(header))\n",
    "    h.show(data, histogram_colors[i])\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#Utility functions \n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x.getNumPartitions()\n",
    "for i in range(0, len(headers)):\n",
    "    rdd_mapped = x.filter(lambda x: x[1][i] == None)\n",
    "    print(headers[i], \"Number of NA:\", rdd_mapped.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
