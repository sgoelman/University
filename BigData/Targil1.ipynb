{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TARGIL No. 1 \n",
    "# By Sahar Goelman\n",
    "# selected database: rasturants.csv\n",
    "#TODO: add link to the resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate that the database file exists otherwise break\n",
    "if  not os.path.isfile(\"tmp.csv\"):\n",
    "    print(\"please add resturants.csv to :\"+os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: rand_code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows loaded: 53577\n"
     ]
    }
   ],
   "source": [
    "#question (1) loading the database\n",
    "csv = sc.textFile(\"tmp.csv\")\n",
    "\n",
    "csv_header = csv.first() \n",
    "print(\"Column names:\",format(csv_header))\n",
    "csv_data = csv.filter(lambda line : line != csv_header) #remove csv headers from data\n",
    "print(\"Number of rows loaded: {}\".format(csv.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FiveHeaders:\n",
    "    def __init__(self):\n",
    "        self.values = []\n",
    "        self.csv_header = dict()\n",
    "    def add_headers(self, key, val):\n",
    "        self.csv_header[key] = val\n",
    "    def get_header(self, key):\n",
    "        return self.csv_header[key]\n",
    "    def get_all_values(self):\n",
    "        self.values = list(self.csv_header.values())\n",
    "        return self.values\n",
    "    def get_index_from_key(self, key):\n",
    "        index_in_header = self.get_header(key)\n",
    "        self.values.index(index_in_header)\n",
    "        return self.values.index(index_in_header)\n",
    "\n",
    "\n",
    "split_headers= csv_header.split(\",\")\n",
    "fiveHeaders = FiveHeaders()\n",
    "headers = ['rand_code'] #, 'business_id','business_id','business_id','business_id']\n",
    "# headers = ['inspection_score', 'business_id','inspection_id','business_postal_code', 'business_phone_number']\n",
    "for header in headers: \n",
    "     fiveHeaders.add_headers(header, split_headers.index(header))\n",
    "\n",
    "# fiveHeaders.get_header('inspection_score')\n",
    "fiveHeaders.get_all_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added unique id at column 0:\nfirst=: (0, ['94119'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataBase: 53576\n"
     ]
    }
   ],
   "source": [
    "#problem number (2):\n",
    "\n",
    "#RDD is assumed to contain an (unique) index column at position 0\n",
    "def get_RDD_row_by_index(rdd, index=0):\n",
    "    nrows = rdd.count()\n",
    "    if index < nrows:\n",
    "        return rdd.filter(lambda kv: kv[0] == index)\n",
    "    return None\n",
    "\n",
    "#RDD is assumed to contain the requested col_nama\n",
    "def get_RDD_col_values(rdd, col_name):\n",
    "    col_index = fv.get_index_from_key(col_name)\n",
    "    return rdd.map(lambda line: line[1][col_index])\n",
    "\n",
    "\n",
    "#add a unique_id and split csv using commas\n",
    "baseData = csv_data.zipWithIndex().map(lambda line: (line[-1],line[:-1][0].split(\",\")))\n",
    "print(\"Added unique id at column 0:\\nfirst=: {}\".format(baseData.first()))\n",
    "# print(\"Added unique id at column 0:\\nfirst[1]: {}\".format(baseData.first()[1]))\n",
    "# print(\"Added unique id at column 0:\\nfirst[1][1]: {}\".format(baseData.first()[1][1]))\n",
    "#test our method to get the n'th row from RDD\n",
    "#print(\"take the {}th row from Data: {}\".format(75, get_RDD_row_by_index(baseData,75).first()))\n",
    "print('number of rows in dataBase: {}'.format(baseData.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header indexes are:[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd[100][0] = 94111\n"
     ]
    }
   ],
   "source": [
    "#problem number (3.a): unique values of the 5 columns \n",
    "#RDD is assumed to contain the requested col_name\n",
    "#row 0 is the first row\n",
    "def get_RDD_col_value(rdd, row_index, col_name):\n",
    "    print (\"header indexes are:{}\".format(fiveHeaders.get_all_values()))\n",
    "    col_index = fiveHeaders.get_index_from_key(col_name)\n",
    "    row = get_RDD_row_by_index(rdd, row_index)\n",
    "    val  = row.first()[1][col_index]\n",
    "    print (\"rdd[{}][{}] = {}\".format(row_index, col_index,val))\n",
    "    #val = row[col_index]\n",
    "    #print(\"value of {} at row {} = {}\".format(col_name, row_index, val))\n",
    "    #return val\n",
    "    #print (\"==>Col index of {} is {}\".format(col_index, col_name))\n",
    "    #return rdd.map(lambda line: line[1][col_index])\n",
    "    #print(get_RDD_col_values(baseData,'business_name'))\n",
    "    #for col_name in fv.get_index_from_key()\n",
    "    #dictionary = {}\n",
    "    #for col_index in fiveHeaders.get_all_values():\n",
    "    #    baseData.map(lambda row: get_RDD_col_values(baseData, col_index))\n",
    "\n",
    "get_RDD_col_value(baseData, 100, 'rand_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering data\n<__main__.Data_Filter object at 0x000002C5123C8240>\nend filtering data\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#alloows counting only numerical columns\n",
    "class Data_Filter():\n",
    "    def __init__(self, header_name):\n",
    "        self.col_indexes = header_name.get_all_values()\n",
    "        self.build_line = self._builder(self.list_creator)\n",
    "        self.build_filter = self._builder(self.create_filter_is_num)\n",
    "        \n",
    "    def _builder(self, func):\n",
    "        return func(self.col_indexes)\n",
    "\n",
    "    def number(self, s):\n",
    "        ret = None\n",
    "        try:\n",
    "            ret = int(s)\n",
    "        except ValueError:\n",
    "            ret = float(s)\n",
    "        finally:\n",
    "            return ret\n",
    "\n",
    "    def is_not_number(self, s):\n",
    "        ret = False\n",
    "        try:\n",
    "            #print(\"value = \".format(s))\n",
    "            if (math.isnan(self.number(s))):  #not a number\n",
    "                ret = True\n",
    "        except:\n",
    "            print(\"exception in is_not_number, s = {}\".format(s))\n",
    "            ret = True\n",
    "        finally:\n",
    "            return ret\n",
    "\n",
    "    def list_creator(self, col_indexes):\n",
    "        def get_unique_line(_line, unique_id, append_num=True):\n",
    "            items = []\n",
    "            for col in col_indexes:\n",
    "                if append_num:\n",
    "                    item = self.number(_line[col])\n",
    "                else:\n",
    "                    item = _line[col]\n",
    "                items.append(item)\n",
    "            return (unique_id, items)\n",
    "        return get_unique_line\n",
    "\n",
    "\n",
    "    def create_filter_is_num(self, col_indexes):\n",
    "\n",
    "        def check_is_number(_line):\n",
    "            ret = True\n",
    "            for col in col_indexes:\n",
    "                try:\n",
    "                    #print (\"_line = {}\".format(_line))\n",
    "                    #print (\"value[{}]: {}\".format(col, _line[col]))\n",
    "                    if (math.isnan(self.number(_line[col]))):\n",
    "                        ret = False\n",
    "                except:\n",
    "                    #TODO\n",
    "                    print('create_filter_is_num caught an exception\\n _line[{}]={}'.format(col, _line[col]))\n",
    "                    ret = False\n",
    "            return ret\n",
    "        return check_is_number\n",
    "\n",
    "print (\"filtering data\")\n",
    "filtered_data = Data_Filter(fiveHeaders)\n",
    "print(filtered_data)\n",
    "print(\"end filtering data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of col_names[rand_code] = 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for col_name in headers: \n",
    "    print(\"index of col_names[{}] = {}\".format(col_name,filtered_data.col_indexes[i]))\n",
    "    i = i + 1\n",
    "    \n",
    "filteredByColumn = baseData.filter(lambda line: filtered_data.build_filter(line[1])).map(lambda line: filtered_data.build_line(line[1], line[0]))\n",
    "\n",
    "def count_distinct(filter_by_column, headerName, key):\n",
    "    res =  filter_by_column.map(lambda pair: pair[1][headerName.get_index_from_key(key)]).distinct().count()\n",
    "    return res\n",
    "def print_distinct(col_name):\n",
    "        cnt = count_distinct(filteredByColumn, fiveHeaders, col_name)\n",
    "        print('Distint values of col: {} = {}'.format(col_name, cnt))\n",
    "        return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distint values of col: rand_code = 52\n"
     ]
    }
   ],
   "source": [
    "#Question 3/a\n",
    "col_distinct_counts = {}\n",
    "for header in headers:\n",
    "    res = print_distinct(header)\n",
    "    col_distinct_counts[header] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of column:rand_code\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-862fa6373510>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilterColumnByHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilteredByColumn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfiveHeaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Histogram of column:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistogram_colors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-862fa6373510>\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, col_name, color)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountAggregateByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-862fa6373510>\u001b[0m in \u001b[0;36mcountAggregateByKey\u001b[1;34m(self, col_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0maggragateByKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountByValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mkeys\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0maggragateByKey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0my_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maggragateByKey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_axis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildObj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#Utility functions to plot histogram\n",
    "class Histogram():\n",
    "\n",
    "    def show(self, col_name, color):\n",
    "        obj = self.countAggregateByKey(col_name)\n",
    "        self.plot(obj,color)\n",
    "    \n",
    "    def countAggregateByKey(self, col_name):\n",
    "        aggragateByKey = col_name.countByValue() \n",
    "        keys  = aggragateByKey.keys()\n",
    "        x_axis = np.array(sorted(keys))\n",
    "        y_axis = np.array([aggragateByKey.get(key) for key in x_axis])\n",
    "        return self.buildObj(x_axis,y_axis)\n",
    "    \n",
    "    def buildObj(self, x_axis,y_axis):\n",
    "        res = dict()\n",
    "        res['x'] = {\n",
    "            'pos': np.arange(len(x_axis)),\n",
    "            'x_axis':x_axis\n",
    "        }\n",
    "        res['y']={\n",
    "            'y_axis':y_axis\n",
    "        }\n",
    "        return res\n",
    "    \n",
    "    def plot(self, obj,color):\n",
    "        y_axis = obj['y']['y_axis']\n",
    "        pos = obj['x']['pos']\n",
    "        x_axis = obj['x']['x_axis']\n",
    "\n",
    "        ax = plt.axes()\n",
    "        ax.set_xticks(pos)\n",
    "        ax.set_xticklabels(x_axis)\n",
    "\n",
    "        plt.bar(pos, y_axis, 0.5, color=color)\n",
    "        plt.xticks(size=16)\n",
    "\n",
    "        fig = matplotlib.pyplot.gcf()\n",
    "        fig.set_size_inches(19, 5)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "#Question 3/b drawing histograms of the 5 columns\n",
    "# get all indexes for a specific col name\n",
    "# we normalize the \"inpection_score\" variable so that \n",
    "def filterColumnByHeader(filteredByColumn,col_names,key):\n",
    "    return filteredByColumn.map(lambda pair: pair[1][col_names.get_index_from_key(key)])\n",
    "\n",
    "histogram_colors = ['red', 'green', 'blue', 'yellow', 'magenta']\n",
    "i = 0\n",
    "h = Histogram()\n",
    "for header in headers:\n",
    "    data = filterColumnByHeader(filteredByColumn,fiveHeaders,header)#\n",
    "    print (\"Histogram of column:{}\".format(header))\n",
    "    h.show(data, histogram_colors[i])\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#Utility functions \n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRecoveryModel:\n",
    "    def __init__(self,v,sigma,median):\n",
    "        items = dict()\n",
    "        items['normal'] = {'mu':v[0]/v[1],'sigma':sigma }\n",
    "        items['median'] = median\n",
    "        self.items = items\n",
    "    def getByType(self,_type):\n",
    "        return self.items[_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRecoveryService():\n",
    "    def __init__(self, baseData, _fiveHeaders):\n",
    "        self.fiveHeaders = _fiveHeaders\n",
    "        self.items = dict()\n",
    "        #hd = self.hd = Data_Filter(fiveHeaders)\n",
    "        hd = self.hd = Data_Filter(_fiveHeaders)\n",
    "        self.shrinkTableAndDarity = baseData.map(lambda line: hd.build_line(line[1], line[0], False))\n",
    "        self.filteredByColumn = baseData.filter(lambda line: hd.build_filter(line[1])).map(\n",
    "            lambda line: hd.build_line(line[1], line[0]))\n",
    "\n",
    "    def fixByType(self, typeFixer, cloumnName):\n",
    "        dataRecoveryModel = self.items[cloumnName]\n",
    "        if typeFixer == 'mean':\n",
    "            metadata = dataRecoveryModel.getByType('normal')\n",
    "            return metadata['mu']\n",
    "        elif typeFixer == 'median':\n",
    "            return dataRecoveryModel.getByType('median')\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def findTheMidle(self, NumOfVal):\n",
    "        if NumOfVal % 2 != 0:\n",
    "            NumOfVal = NumOfVal + 1\n",
    "        return NumOfVal / 2\n",
    "\n",
    "    def calcDataRecoveryTypes(self, columnName):\n",
    "        hd = self.hd\n",
    "        fv = self.fiveHeaders\n",
    "        v = self.filteredByColumn.map(lambda pair: (pair[1][fv.get_index_from_key(columnName)], 1)).reduce(\n",
    "            lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "        n = self.findTheMidle(v[1])\n",
    "        median = self.filteredByColumn.map(lambda pair: (pair[1][fv.get_index_from_key(columnName)])) \\\n",
    "            .sortBy(lambda item: item).zipWithIndex().filter(lambda pair: pair[1] == n).collect()[0][0]\n",
    "        self.items[columnName] = DataRecoveryModel(v, 1, median)\n",
    "\n",
    "    def normelizeColumn(self, cloumnName, sigma):\n",
    "        fv = self.fiveHeaders\n",
    "        dataRecoveryModel = self.items[cloumnName]\n",
    "        metadata = dataRecoveryModel.getByType('normal')\n",
    "        mu = metadata['mu']\n",
    "        return self.filteredByColumn.map(\n",
    "          lambda pair: normalizeFixer(pair[1][fv.get_index_from_key(cloumnName)], mu, sigma))\n",
    "    \n",
    "    def fixCellsByType(self, typeFixer, columnName):\n",
    "        fv = self.fiveHeaders\n",
    "        hd = self.hd\n",
    "        fixedValue = self.fixByType(typeFixer, columnName)\n",
    "        return self.shrinkTableAndDarity.map(\n",
    "                lambda pair: fixCellsByTypePrivate(pair[1][fv.get_index_from_key(columnName)], fixedValue, hd))\n",
    "\n",
    "def normalizeFixer(x, mu, sigma):\n",
    "    return (x - mu)/sigma    \n",
    "    \n",
    "def fixCellsByTypePrivate(cell,fixedValue,hd):\n",
    "    isNotANumber = True\n",
    "    isNotANumber = hd.is_not_number(cell)\n",
    "    if isNotANumber :\n",
    "        cell = fixedValue\n",
    "    else: \n",
    "        cell = hd.num(cell)\n",
    "    return cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DataRecoveryService' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-69740774e659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#DRService = DataRecoveryService(baseData, fiveHeaders)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mDRService\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataRecoveryService\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataRecoveryService' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "fv = FiveHeaders()\n",
    "fv.add_headers('rand_code', 0)\n",
    "print(fv.get_all_values())\n",
    "\n",
    "#DRService = DataRecoveryService(baseData, fiveHeaders)\n",
    "DRService = DataRecoveryService(baseData, fv)\n",
    "\n",
    "hs = Histogram()\n",
    "i = 0\n",
    "DRService.calcDataRecoveryTypes(col_name)\n",
    "print(\"Histogram of column:{}\".format(col_name))\n",
    "hs.show(DRService.fixCellsByType('mean', col_name), histogram_colors[i])\n",
    "i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
