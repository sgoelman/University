{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import string\n",
    "\n",
    "wine_data =spark.read.option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|         description|\n",
      "+-------+--------------------+\n",
      "|  count|              129974|\n",
      "|   mean|                20.0|\n",
      "| stddev|                 NaN|\n",
      "|    min|         \"\"\"Chremisa|\n",
      "|    max|“Wow” is the firs...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_data.describe('description').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|              points|\n",
      "+-------+--------------------+\n",
      "|  count|              129966|\n",
      "|   mean|   88.44617681462783|\n",
      "| stddev|  3.0478934351221008|\n",
      "|    min| and it doesn't s...|\n",
      "|    max|              Umriss|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_data.describe('points').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- designation: string (nullable = true)\n",
      " |-- points: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- region_1: string (nullable = true)\n",
      " |-- region_2: string (nullable = true)\n",
      " |-- taster_name: string (nullable = true)\n",
      " |-- taster_twitter_handle: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      " |-- winery: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . clustering\n",
    "# 2 . sarcazem\n",
    "# 3 . support more features\n",
    "# 4 . concat last work to this file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is the average length of review? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129975"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data - missing values and duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129965"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = wine_data.select('points','description').dropna()\n",
    "wine_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove shorts reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine_data.where(length(col('description'))>=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129728"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean our data, here we’re gonna remove punctuations and empty spaces.\n",
    "def removePunctuation(column):\n",
    "#     return column.translate(str.maketrans('', '', string.punctuation))\n",
    "    return trim(lower(regexp_replace(column, '[^\\sa-zA-Z0-9]', ''))).alias('review')\n",
    "\n",
    "wine = wine_data.select([removePunctuation(wine_data['description']),col(\"points\").alias(\"label\")])\n",
    "\n",
    "# we choose  to work on positive negtive problem\n",
    "wine = wine.withColumn(\"label\", when(col(\"label\")>80, 1.0).otherwise(0.0))\n",
    "# wine.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------------------------+\n",
      "|avg(descriptionWordCount)|count(descriptionWordCount)|\n",
      "+-------------------------+---------------------------+\n",
      "|        40.43258201776024|                     129728|\n",
      "+-------------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "df = wine_data.withColumn('descriptionWordCount', f.size(f.split(f.col('description'), ' ')))\n",
    "df.agg(f.mean('descriptionWordCount'), f.count('descriptionWordCount')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocecing\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split each sentence into words, also called word tokenization.\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"split_sentence_into_words\")\n",
    "wordsDF = tokenizer.transform(wine)\n",
    "# wordsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"split_sentence_into_words\", outputCol=\"clean_word\")\n",
    "wordsDF2 = remover.transform(wordsDF)\n",
    "# wordsDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------------+--------------------+--------------------+\n",
      "|              review|label|split_sentence_into_words|          clean_word|            features|\n",
      "+--------------------+-----+-------------------------+--------------------+--------------------+\n",
      "|aromas include tr...|  1.0|     [aromas, include,...|[aromas, include,...|(262144,[11076,21...|\n",
      "|this is ripe and ...|  1.0|     [this, is, ripe, ...|[ripe, fruity, wi...|(262144,[5460,213...|\n",
      "|tart and snappy t...|  1.0|     [tart, and, snapp...|[tart, snappy, fl...|(262144,[21336,25...|\n",
      "|pineapple rind le...|  1.0|     [pineapple, rind,...|[pineapple, rind,...|(262144,[9575,251...|\n",
      "|much like the reg...|  1.0|     [much, like, the,...|[much, like, regu...|(262144,[16422,32...|\n",
      "|blackberry and ra...|  1.0|     [blackberry, and,...|[blackberry, rasp...|(262144,[3521,148...|\n",
      "|heres a bright in...|  1.0|     [heres, a, bright...|[heres, bright, i...|(262144,[11076,12...|\n",
      "|this dry and rest...|  1.0|     [this, dry, and, ...|[dry, restrained,...|(262144,[21336,51...|\n",
      "|savory dried thym...|  1.0|     [savory, dried, t...|[savory, dried, t...|(262144,[5358,538...|\n",
      "|this has great de...|  1.0|     [this, has, great...|[great, depth, fl...|(262144,[5460,213...|\n",
      "|soft supple plum ...|  1.0|     [soft, supple, pl...|[soft, supple, pl...|(262144,[12531,22...|\n",
      "|this is a dry win...|  1.0|     [this, is, a, dry...|[dry, wine, spicy...|(262144,[26395,28...|\n",
      "|slightly reduced ...|  1.0|     [slightly, reduce...|[slightly, reduce...|(262144,[551,4461...|\n",
      "|this is dominated...|  1.0|     [this, is, domina...|[dominated, oak, ...|(262144,[23205,76...|\n",
      "|building on 150 y...|  1.0|     [building, on, 15...|[building, 150, y...|(262144,[25175,27...|\n",
      "|zesty orange peel...|  1.0|     [zesty, orange, p...|[zesty, orange, p...|(262144,[56749,72...|\n",
      "|baked plum molass...|  1.0|     [baked, plum, mol...|[baked, plum, mol...|(262144,[2053,112...|\n",
      "|raw blackcherry a...|  1.0|     [raw, blackcherry...|[raw, blackcherry...|(262144,[5460,121...|\n",
      "|desiccated blackb...|  1.0|     [desiccated, blac...|[desiccated, blac...|(262144,[3766,178...|\n",
      "|red fruit aromas ...|  1.0|     [red, fruit, arom...|[red, fruit, arom...|(262144,[12346,22...|\n",
      "+--------------------+-----+-------------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to binary\n",
    "hashingTF_binary = HashingTF(inputCol=\"clean_word\", outputCol=\"features\", binary = True)\n",
    "words_binary_df = hashingTF_binary.transform(wordsDF2)\n",
    "words_binary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Split data into training and testing set \n",
    "(training, test) = words_binary_df.randomSplit([0.7, 0.3],seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    def run(self,training,test):\n",
    "        fitModel = self.model.fit(training)\n",
    "        self.predictions = fitModel.transform(test)\n",
    "    def classification_evaluators(self):\n",
    "        # Evaluate result with accuracy\n",
    "        evaluator1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        accuracy = evaluator1.evaluate(self.predictions)\n",
    "        print(\"Model Accuracy: \", accuracy)\n",
    "\n",
    "        # Evaluate result with ROC\n",
    "        evaluator2 = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "        AUC = evaluator2.evaluate(self.predictions)\n",
    "        print(\"area under ROC: \", AUC)\n",
    "        \n",
    "    def get_score(self):\n",
    "        lr_label_predictions_df = self.predictions.select([\"label\", \"prediction\"])\n",
    "\n",
    "        tp_count = lr_label_predictions_df.filter(\"label=1.0 and prediction=1.0\").count()\n",
    "        \n",
    "        prediction_one = lr_label_predictions_df.filter(\"prediction=1.0\").count()\n",
    "        precision = float(tp_count) / prediction_one\n",
    "\n",
    "        label_one = lr_label_predictions_df.filter(\"label=1.0\").count()\n",
    "        recall = float(tp_count) / label_one\n",
    "\n",
    "        print(\"recall\", recall, \", precision\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes on boolean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.9971985195846612\n",
      "area under ROC:  0.23404462093627212\n",
      "recall 1.0 , precision 0.9971985195846612\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "naiveBayesEvaluator = Evaluator(nb)\n",
    "naiveBayesEvaluator.run(training,test)\n",
    "naiveBayesEvaluator.classification_evaluators()\n",
    "naiveBayesEvaluator.get_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression on boolean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.9955022103423461\n",
      "area under ROC:  0.8867652646869035\n",
      "recall 0.9980154127683704 , precision 0.9974755280783102\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=10)\n",
    "logisticRegressionEvaluator = Evaluator(lr)\n",
    "logisticRegressionEvaluator.run(training,test)\n",
    "logisticRegressionEvaluator.classification_evaluators()\n",
    "logisticRegressionEvaluator.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "class EvaluatorClustering():\n",
    "    def __init__(self,model):\n",
    "        self.modelInstance = model\n",
    "    def run(self,featureTable,reviewTable):\n",
    "        self.model =  self.modelInstance.fit(featureTable)\n",
    "        self.predictions = self.model.transform(reviewTable)\n",
    "\n",
    "    def evaluators(self):\n",
    "        evaluator = ClusteringEvaluator()\n",
    "        silhouette = evaluator.evaluate(self.predictions)\n",
    "        print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "        # Shows the result.\n",
    "        centers = self.model.clusterCenters()\n",
    "        print(\"Cluster Centers: \")\n",
    "        for center in centers:\n",
    "            print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.0403100977032412\n",
      "Cluster Centers: \n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "ec = EvaluatorClustering(KMeans().setK(2).setSeed(100))\n",
    "featureTable = words_binary_df.select('features')\n",
    "reviewTable = words_binary_df.select(['label','review','features'])\n",
    "\n",
    "ec.run(featureTable,reviewTable)\n",
    "ec.evaluators()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating tfidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------------+--------------------+\n",
      "|              review|label|split_sentence_into_words|          clean_word|\n",
      "+--------------------+-----+-------------------------+--------------------+\n",
      "|aromas include tr...|  1.0|     [aromas, include,...|[aromas, include,...|\n",
      "|this is ripe and ...|  1.0|     [this, is, ripe, ...|[ripe, fruity, wi...|\n",
      "|tart and snappy t...|  1.0|     [tart, and, snapp...|[tart, snappy, fl...|\n",
      "|pineapple rind le...|  1.0|     [pineapple, rind,...|[pineapple, rind,...|\n",
      "|much like the reg...|  1.0|     [much, like, the,...|[much, like, regu...|\n",
      "|blackberry and ra...|  1.0|     [blackberry, and,...|[blackberry, rasp...|\n",
      "|heres a bright in...|  1.0|     [heres, a, bright...|[heres, bright, i...|\n",
      "|this dry and rest...|  1.0|     [this, dry, and, ...|[dry, restrained,...|\n",
      "|savory dried thym...|  1.0|     [savory, dried, t...|[savory, dried, t...|\n",
      "|this has great de...|  1.0|     [this, has, great...|[great, depth, fl...|\n",
      "|soft supple plum ...|  1.0|     [soft, supple, pl...|[soft, supple, pl...|\n",
      "|this is a dry win...|  1.0|     [this, is, a, dry...|[dry, wine, spicy...|\n",
      "|slightly reduced ...|  1.0|     [slightly, reduce...|[slightly, reduce...|\n",
      "|this is dominated...|  1.0|     [this, is, domina...|[dominated, oak, ...|\n",
      "|building on 150 y...|  1.0|     [building, on, 15...|[building, 150, y...|\n",
      "|zesty orange peel...|  1.0|     [zesty, orange, p...|[zesty, orange, p...|\n",
      "|baked plum molass...|  1.0|     [baked, plum, mol...|[baked, plum, mol...|\n",
      "|raw blackcherry a...|  1.0|     [raw, blackcherry...|[raw, blackcherry...|\n",
      "|desiccated blackb...|  1.0|     [desiccated, blac...|[desiccated, blac...|\n",
      "|red fruit aromas ...|  1.0|     [red, fruit, arom...|[red, fruit, arom...|\n",
      "+--------------------+-----+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------------+--------------------+--------------------+\n",
      "|              review|label|split_sentence_into_words|          clean_word|                  tf|\n",
      "+--------------------+-----+-------------------------+--------------------+--------------------+\n",
      "|aromas include tr...|  1.0|     [aromas, include,...|[aromas, include,...|(262144,[11076,21...|\n",
      "|this is ripe and ...|  1.0|     [this, is, ripe, ...|[ripe, fruity, wi...|(262144,[5460,213...|\n",
      "|tart and snappy t...|  1.0|     [tart, and, snapp...|[tart, snappy, fl...|(262144,[21336,25...|\n",
      "|pineapple rind le...|  1.0|     [pineapple, rind,...|[pineapple, rind,...|(262144,[9575,251...|\n",
      "|much like the reg...|  1.0|     [much, like, the,...|[much, like, regu...|(262144,[16422,32...|\n",
      "|blackberry and ra...|  1.0|     [blackberry, and,...|[blackberry, rasp...|(262144,[3521,148...|\n",
      "|heres a bright in...|  1.0|     [heres, a, bright...|[heres, bright, i...|(262144,[11076,12...|\n",
      "|this dry and rest...|  1.0|     [this, dry, and, ...|[dry, restrained,...|(262144,[21336,51...|\n",
      "|savory dried thym...|  1.0|     [savory, dried, t...|[savory, dried, t...|(262144,[5358,538...|\n",
      "|this has great de...|  1.0|     [this, has, great...|[great, depth, fl...|(262144,[5460,213...|\n",
      "|soft supple plum ...|  1.0|     [soft, supple, pl...|[soft, supple, pl...|(262144,[12531,22...|\n",
      "|this is a dry win...|  1.0|     [this, is, a, dry...|[dry, wine, spicy...|(262144,[26395,28...|\n",
      "|slightly reduced ...|  1.0|     [slightly, reduce...|[slightly, reduce...|(262144,[551,4461...|\n",
      "|this is dominated...|  1.0|     [this, is, domina...|[dominated, oak, ...|(262144,[23205,76...|\n",
      "|building on 150 y...|  1.0|     [building, on, 15...|[building, 150, y...|(262144,[25175,27...|\n",
      "|zesty orange peel...|  1.0|     [zesty, orange, p...|[zesty, orange, p...|(262144,[56749,72...|\n",
      "|baked plum molass...|  1.0|     [baked, plum, mol...|[baked, plum, mol...|(262144,[2053,112...|\n",
      "|raw blackcherry a...|  1.0|     [raw, blackcherry...|[raw, blackcherry...|(262144,[5460,121...|\n",
      "|desiccated blackb...|  1.0|     [desiccated, blac...|[desiccated, blac...|(262144,[3766,178...|\n",
      "|red fruit aromas ...|  1.0|     [red, fruit, arom...|[red, fruit, arom...|(262144,[12346,22...|\n",
      "+--------------------+-----+-------------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol = \"clean_word\", outputCol=\"tf\")\n",
    "wordsDF = hashingTF.transform(wordsDF2)\n",
    "wordsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------------+--------------------+--------------------+--------------------+\n",
      "|              review|label|split_sentence_into_words|          clean_word|                  tf|            features|\n",
      "+--------------------+-----+-------------------------+--------------------+--------------------+--------------------+\n",
      "|aromas include tr...|  1.0|     [aromas, include,...|[aromas, include,...|(262144,[11076,21...|(262144,[11076,21...|\n",
      "|this is ripe and ...|  1.0|     [this, is, ripe, ...|[ripe, fruity, wi...|(262144,[5460,213...|(262144,[5460,213...|\n",
      "|tart and snappy t...|  1.0|     [tart, and, snapp...|[tart, snappy, fl...|(262144,[21336,25...|(262144,[21336,25...|\n",
      "|pineapple rind le...|  1.0|     [pineapple, rind,...|[pineapple, rind,...|(262144,[9575,251...|(262144,[9575,251...|\n",
      "|much like the reg...|  1.0|     [much, like, the,...|[much, like, regu...|(262144,[16422,32...|(262144,[16422,32...|\n",
      "|blackberry and ra...|  1.0|     [blackberry, and,...|[blackberry, rasp...|(262144,[3521,148...|(262144,[3521,148...|\n",
      "|heres a bright in...|  1.0|     [heres, a, bright...|[heres, bright, i...|(262144,[11076,12...|(262144,[11076,12...|\n",
      "|this dry and rest...|  1.0|     [this, dry, and, ...|[dry, restrained,...|(262144,[21336,51...|(262144,[21336,51...|\n",
      "|savory dried thym...|  1.0|     [savory, dried, t...|[savory, dried, t...|(262144,[5358,538...|(262144,[5358,538...|\n",
      "|this has great de...|  1.0|     [this, has, great...|[great, depth, fl...|(262144,[5460,213...|(262144,[5460,213...|\n",
      "|soft supple plum ...|  1.0|     [soft, supple, pl...|[soft, supple, pl...|(262144,[12531,22...|(262144,[12531,22...|\n",
      "|this is a dry win...|  1.0|     [this, is, a, dry...|[dry, wine, spicy...|(262144,[26395,28...|(262144,[26395,28...|\n",
      "|slightly reduced ...|  1.0|     [slightly, reduce...|[slightly, reduce...|(262144,[551,4461...|(262144,[551,4461...|\n",
      "|this is dominated...|  1.0|     [this, is, domina...|[dominated, oak, ...|(262144,[23205,76...|(262144,[23205,76...|\n",
      "|building on 150 y...|  1.0|     [building, on, 15...|[building, 150, y...|(262144,[25175,27...|(262144,[25175,27...|\n",
      "|zesty orange peel...|  1.0|     [zesty, orange, p...|[zesty, orange, p...|(262144,[56749,72...|(262144,[56749,72...|\n",
      "|baked plum molass...|  1.0|     [baked, plum, mol...|[baked, plum, mol...|(262144,[2053,112...|(262144,[2053,112...|\n",
      "|raw blackcherry a...|  1.0|     [raw, blackcherry...|[raw, blackcherry...|(262144,[5460,121...|(262144,[5460,121...|\n",
      "|desiccated blackb...|  1.0|     [desiccated, blac...|[desiccated, blac...|(262144,[3766,178...|(262144,[3766,178...|\n",
      "|red fruit aromas ...|  1.0|     [red, fruit, arom...|[red, fruit, arom...|(262144,[12346,22...|(262144,[12346,22...|\n",
      "+--------------------+-----+-------------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"tf\", outputCol=\"features\")\n",
    "idfModel = idf.fit(wordsDF)\n",
    "words_tf_idf_DF = idfModel.transform(wordsDF)\n",
    "words_tf_idf_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = words_tf_idf_DF.randomSplit([0.7, 0.3],seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes on tdidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.9971728179294747\n",
      "area under ROC:  0.3772172317881077\n",
      "recall 0.999948452279698 , precision 0.9972240071970184\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "naiveBayesEvaluator = Evaluator(nb)\n",
    "naiveBayesEvaluator.run(training,test)\n",
    "naiveBayesEvaluator.classification_evaluators()\n",
    "naiveBayesEvaluator.get_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression on tdidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.9956564202734656\n",
      "area under ROC:  0.881628463421572\n",
      "recall 0.9981700559292765 , precision 0.9974759181991449\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=10)\n",
    "logisticRegressionEvaluator = Evaluator(lr)\n",
    "logisticRegressionEvaluator.run(training,test)\n",
    "logisticRegressionEvaluator.classification_evaluators()\n",
    "logisticRegressionEvaluator.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.0206856609768209\n",
      "Cluster Centers: \n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "ec = EvaluatorClustering(KMeans().setK(2).setSeed(1))\n",
    "featureTable = words_tf_idf_DF.select('features')\n",
    "reviewTable = words_tf_idf_DF.select(['label','review','features'])\n",
    "\n",
    "ec.run(featureTable,reviewTable)\n",
    "ec.evaluators()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
