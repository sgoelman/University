{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(142, 'rentdirect.com'), (142, 'staple.com')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# todo: change trashold\n",
    "SUPPORT_TRASHOLD=0.001\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "import time\n",
    "# df = spark.read.text(\"user-searches-min.txt\")\n",
    "import re\n",
    "\n",
    "def removeTimestamp(row):\n",
    "    find = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "    start = re.search(find,row).start()\n",
    "    return row[0:start]\n",
    "\n",
    "def spliteToUserIdAndUserSearch(row):\n",
    "    row = row.split(\"\\t\", 1)\n",
    "    row[1] =  row[1].rstrip('\\t')\n",
    "    return (int(row[0]),row[1])\n",
    "\n",
    "def uniqueList(line):\n",
    "    uniqueSearches = set(line[1])\n",
    "    newLine = [line[0],list(uniqueSearches)]\n",
    "    return newLine\n",
    "\n",
    "log_txt=sc.textFile(\"C:\\\\Users\\\\sgoel\\\\PycharmProjects\\\\University\\\\BigData\\\\TargilTwo\\\\test.txt\")\n",
    "header = log_txt.first()\n",
    "\n",
    "#filter out the header, make sure the rest looks correct\n",
    "log_txt = log_txt.filter(lambda line: line != header)\n",
    "logSearch = log_txt.map(lambda line: spliteToUserIdAndUserSearch(removeTimestamp(line))).distinct()\n",
    "print(logSearch.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(142, 'rentdirect.com'), (142, 'staple.com')]\n"
     ]
    }
   ],
   "source": [
    "print(logSearch.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# number of users\n",
    "totalOfTransactions = logSearch.groupByKey().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(totalOfTransactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rentdirect.com', 0.25),\n ('staple.com', 0.25),\n ('www.newyorklawyersite.com', 0.25),\n ('207 ad2d 530', 0.25),\n ('frankmellace.com', 0.25),\n ('ucs.ljx.com', 0.25),\n ('attornyleslie.com', 0.25),\n ('merit release appearance', 0.25),\n ('www.bonsai.wbff.org', 0.25),\n ('loislaw.com', 0.25)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the user id -> return only query\n",
    "\n",
    "all_queries = logSearch.map(lambda line: line[1])\n",
    "# count how much time query is show for all the user divide by number of users\n",
    "rdd_query_count = all_queries.map(lambda q: (q, 1) ).reduceByKey(lambda c1,c2: c1+c2 ) \\\n",
    "                                                    .map(lambda x: (x[0], x[1] / totalOfTransactions)) \\\n",
    "                                                    .filter(lambda x: x[1] > SUPPORT_TRASHOLD)\n",
    "\n",
    "# rdd_query_count is list of queries that pass the thrasholds of support\n",
    "rdd_query_count.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'myspace.com', 'dfdf', 'vaniqa.comh', 'www.collegeucla.edu', 'www.elaorg']\n"
     ]
    }
   ],
   "source": [
    "# get the set of all queries\n",
    "# todo: create join instead of collect \n",
    "validItems = rdd_query_count.map(lambda x:x[0]).collect()\n",
    "print(validItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_queries_by_support_thrasholds(inValidList,validItems):\n",
    "    return [s for s in inValidList if s in validItems]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ['a', 'b', 'c', 'dfdf', 'www.elaorg']),\n",
       " (2, ['b', 'a', 'www.collegeucla.edu'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = logSearch.groupByKey().mapValues(list).filter(lambda kv: len(kv[1]) > 1)  \n",
    "# remove all transactions that are not supported - if not in valid items will be removed - if query passed the trusthold \n",
    "user_query = user_query.map(lambda t: (t[0],include_queries_by_support_thrasholds(t[1],validItems)))\n",
    "user_query.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b'),\n",
       " ('a', 'c'),\n",
       " ('a', 'dfdf'),\n",
       " ('a', 'www.elaorg'),\n",
       " ('b', 'c'),\n",
       " ('b', 'dfdf'),\n",
       " ('b', 'www.elaorg'),\n",
       " ('c', 'dfdf'),\n",
       " ('c', 'www.elaorg'),\n",
       " ('dfdf', 'www.elaorg'),\n",
       " ('b', 'a'),\n",
       " ('b', 'www.collegeucla.edu'),\n",
       " ('a', 'www.collegeucla.edu'),\n",
       " ('a', 'c'),\n",
       " ('a', 'myspace.com'),\n",
       " ('a', 'vaniqa.comh'),\n",
       " ('c', 'myspace.com'),\n",
       " ('c', 'vaniqa.comh'),\n",
       " ('myspace.com', 'vaniqa.comh')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_pairs(arr):\n",
    "        result = []\n",
    "        # all posible pairs for each user \n",
    "        for p1 in range(len(arr)):\n",
    "                for p2 in range(p1+1,len(arr)):\n",
    "                        result.append((arr[p1],arr[p2]))\n",
    "        return result\n",
    "# \n",
    "all_queries_pairs_tuples = user_query.map(lambda kv: kv[1]).flatMap(lambda arr: get_all_pairs(arr))\n",
    "all_queries_pairs_tuples.take(50)\n",
    "# userId | a, b ,c ,d\n",
    "# 1| 1,1,0,0->a,b\n",
    "# 2|0,1,1,0->b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'b'), 0.6666666666666666), (('a', 'c'), 0.6666666666666666)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a,b) is the same as (b,a)- so we need to remove the same pairs\n",
    "def sort_small_list(arr):\n",
    "    if(arr[0] <= arr[1]):\n",
    "        return arr\n",
    "    return [arr[1],arr[0]]\n",
    "# the sort is for (a,b) (b,a) = > (a,b) (a,b) => ((a,b),2)\n",
    "all_queries_tuples_sorted = all_queries_pairs_tuples.map(lambda kv: sort_small_list(list(kv))) \\\n",
    "                                                .map(lambda arr: (arr[0],arr[1]) )\n",
    "\n",
    "all_queries_pairs_tuples_count = all_queries_tuples_sorted.map(lambda kv: (kv,1)) \\\n",
    "                                                    .reduceByKey(lambda c1,c2: c1+c2 )\\\n",
    "                                                    .filter(lambda kv: kv[1] > 1) \\\n",
    "                                                    .map(lambda x: (x[0], x[1] / totalOfTransactions)) \n",
    "\n",
    "\n",
    "all_queries_pairs_tuples_count.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('a', 'b'), 0.6666666666666666), ('a', 1.0)),\n",
       " ((('a', 'b'), 0.6666666666666666), ('b', 0.6666666666666666)),\n",
       " ((('a', 'b'), 0.6666666666666666), ('c', 0.6666666666666666))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: replace cartesian with join \n",
    "\n",
    "rdd_queries_tuples_cartesian = all_queries_pairs_tuples_count.cartesian(rdd_query_count)\n",
    "rdd_queries_tuples_cartesian.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'b', 0.6666666666666666), ('a', 'c', 0.6666666666666666)]\n",
      "[('b', 'a', 1.0), ('c', 'a', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "# this command calculate XUY/X by taking all lines that ((x ,y , number of suply(xUy)),(z ,number of suply(z))) when z ==x\n",
    "rdd_join_left = rdd_queries_tuples_cartesian.filter(lambda lr: lr[0][0][0] == lr[1][0]) \\\n",
    "                                            .map(lambda lr: (lr[0][0][0],lr[0][0][1],float(lr[0][1]) / lr[1][1]))\n",
    "\n",
    "print(rdd_join_left.take(5))\n",
    "# this command take XUY/Y\n",
    "\n",
    "rdd_join_right = rdd_queries_tuples_cartesian.filter(lambda lr: lr[0][0][1] == lr[1][0])\\\n",
    "                                             .map(lambda lr: (lr[0][0][1], lr[0][0][0], float(lr[0][1]) / lr[1][1]))\n",
    "print(rdd_join_right.take(5))\n",
    "\n",
    "rdd_query_conf = sc.union([rdd_join_left, rdd_join_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 00:00:06\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(end - start))\n",
    "print(\"elapsed time: %s\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
